# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/1a_load.ipynb (unless otherwise specified).

__all__ = ['load_raw_ideas_tree', 'load_raw_ideas_dir', 'remove_unwanted_features', 'tag_columns']

# Cell
# export

import pandas
import os
import numpy
import seaborn
import logging

# Cell
import fcsparser
from pathlib import Path

# Cell

def load_raw_ideas_tree(tree_path, load_labels=False):
    logger = logging.getLogger(__name__)

    data = []
    columns = set()

    for timepoint_path in [p for p in os.listdir(tree_path) if os.path.isdir(os.path.join(tree_path, p))]:
        for replicate_path in os.listdir(os.path.join(tree_path, timepoint_path)):
            path = os.path.join(tree_path, timepoint_path, replicate_path)

            if not os.path.isfile(os.path.join(path, "focused.fcs")):
                continue

            logger.info(f"Loading dir {path}")

            meta, features = fcsparser.parse(os.path.join(path, "focused.fcs"))
            features["meta_timepoint"] = timepoint_path
            features["meta_replicate"] = replicate_path

            if load_labels:
                features["meta_label"] = "unknown"
                for file in [p for p in os.listdir(path) if p.endswith(".txt")]:
                    label = os.path.splitext(file)[0]
                    object_numbers = pandas.read_csv(os.path.join(path, file), skiprows=1, delimiter="\t", index_col=0).index
                    features.loc[object_numbers, "meta_label"] = label

            logger.debug(f"Loaded dataframe with shape {features.shape}")

            if len(columns) == 0:
                columns |= set(features.columns.values.tolist())
            else:
                columns &= set(features.columns.values.tolist())

            data.append(features)

    return pandas.concat(data)[columns]

# Cell

def load_raw_ideas_dir(path, feature_postfix, label_postfixes=[]):
    logger = logging.getLogger(__name__)

    path = Path(path)
    dfs = []
    for cif in path.rglob("*.cif"):
        logger.info(cif)
        fcs = (cif.parent / (str(cif.stem) + "_%s" % feature_postfix)).with_suffix(".fcs")
        meta, features = fcsparser.parse(fcs)
        features["meta_timepoint"] = cif.parts[-1].split("_")[1]
        features["meta_replicate"] = "R"+cif.parts[-1].split("_")[0][1]
        features["meta_group"] = cif.parts[-2]
        features["meta_label"] = "-"
        for label_postfix in label_postfixes:
            label_file = (cif.parent / (str(cif.stem) + "_%s" % label_postfix)).with_suffix(".txt")
            object_numbers = pandas.read_csv(label_file, skiprows=1, delimiter="\t", index_col=0).index
            features.loc[object_numbers, "meta_label"] = label_postfix

        dfs.append(features)

    return pandas.concat(dfs)

# Cell
def remove_unwanted_features(df):
    todrop = df.filter(regex="(?i).*(raw|bkgd).*").columns

    return df.drop(columns=todrop)

# Cell

def tag_columns(df):
    columns = df.columns.values.tolist()
    system_cols = ["Flow Speed", "Time", "Object Number"]
    for c in system_cols:
        if c in columns:
            columns[columns.index(c)] = "meta_"+c

    for c in columns:
        if not "meta_" in c:
            columns[columns.index(c)] = "feat_"+c

    df.columns = columns
    return df