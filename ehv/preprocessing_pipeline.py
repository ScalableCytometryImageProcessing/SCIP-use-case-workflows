# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/preprocessing/3c_preprocessing_pipeline_low.ipynb (unless otherwise specified).

__all__ = ['GroupedTransformer', 'ColumnTransformer', 'PandasVarianceThreshold', 'make_pipeline_1',
           'GroupedTransformer', 'ColumnTransformer', 'PandasVarianceThreshold']

# Cell
# export

import pandas
import os
import numpy
import seaborn
import logging
import matplotlib.pyplot as plt
from matplotlib import cm
import matplotlib
from importlib import reload
from ehv import core
from joblib import load, dump
from pathlib import Path
import uuid
import re
import scipy

from ehv import load as e_load, core

plt.rcParams['figure.facecolor'] = 'white'

numpy.random.seed(42)

# Cell
from ehv import correlation
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, Normalizer
from sklearn.feature_selection import VarianceThreshold
from sklearn.decomposition import FastICA, PCA, KernelPCA
from umap import UMAP
from multiprocessing import Pool, cpu_count

# Cell
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer, make_column_selector
from sklearn.base import TransformerMixin, BaseEstimator, clone

# Cell
class GroupedTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, base_transformer, group_key, n_jobs=-1):
        self.base_transformer = base_transformer
        self.group_key = group_key
        self.n_jobs = n_jobs if n_jobs >= 1 else cpu_count()

    def fit(self, df):
        self.transformers = {}
        with Pool(processes=self.n_jobs) as pool:
            for idx, gdf in df.groupby(self.group_key):
                self.transformers[idx] = pool.apply_async(clone(self.base_transformer).fit, args=(gdf.drop(columns=self.group_key),))
            for k,v in self.transformers.items():
                self.transformers[k] = v.get()
        return self

    def transform(self, df):
        columns = df.drop(columns=self.group_key).columns
        dfs = []
        with Pool(processes=self.n_jobs) as pool:
            promises = []
            for idx, gdf in df.groupby(self.group_key):
                promises.append(pool.apply_async(self.transformers[idx].transform, args=(gdf[columns],)))
            for (promise, (idx, gdf)) in zip(promises, df.groupby(self.group_key)):
                gdf[columns] = promise.get()
                dfs.append(gdf)
        return pandas.concat(dfs)

class ColumnTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, transformer, col_selector, append=False, drop_remainder=False):
        self.transformer = transformer
        self.col_selector = col_selector
        self.append = append
        self.drop_remainder = drop_remainder

    def fit(self, df, y=None):
        self.transformer.fit(df[self.col_selector(df)])
        return self

    def transform(self, df, y=None):

        data = self.transformer.transform(df[self.col_selector(df)])
        if hasattr(data, "iloc"):
            tmp_df = data
        else:
            if len(self.col_selector(df)) == data.shape[1]:
                columns = self.col_selector(df)
            else:
                columns = ["feat_%s_%s" % (self.transformer.__class__.__name__.lower(), i) for i in range(data.shape[1])]

            tmp_df = pandas.DataFrame(
                data = data,
                columns = columns,
                index = df.index
            )

        if self.append:
            return pandas.concat([df, tmp_df], axis=1)
        elif self.drop_remainder:
            return pandas.concat([df.drop(columns=self.col_selector(df)), tmp_df], axis=1)
        else:
            df = df.copy()
            df[self.col_selector(df)] = tmp_df
            return df


class PandasVarianceThreshold(BaseEstimator, TransformerMixin):
    def __init__(self, thresh=0.0):
        self.thresh = thresh
        self.var = VarianceThreshold()

    def fit(self, X):
        self.var.fit(X)
        return self

    def transform(self, X):
        return X[X.columns[self.var.get_support()]]

# Cell
def make_pipeline_1():
    feat_selector = make_column_selector(pattern="feat")
    meta_selector = make_column_selector(pattern="^(feat|meta_timepoint).*")
    return Pipeline([
        ("zero_var", ColumnTransformer(PandasVarianceThreshold(), feat_selector, drop_remainder=True)),
        ("correlation", ColumnTransformer(correlation.Correlation(0.92), feat_selector, drop_remainder=True)),
        ("normalize", ColumnTransformer(Normalizer(), feat_selector)),
        ("power_transform", ColumnTransformer(PowerTransformer(), feat_selector)),
        ("pca", ColumnTransformer(PCA(n_components=0.95, random_state=42), feat_selector, append=True)),
        ("umap", ColumnTransformer(UMAP(n_components=2, random_state=42, metric="cosine"), make_column_selector(pattern="feat_pca"), append=True))
    ])

# Cell
# export

import pandas
import os
import numpy
import seaborn
import logging
import matplotlib.pyplot as plt
from matplotlib import cm
import matplotlib
from importlib import reload
from ehv import core
from joblib import load, dump
from pathlib import Path
import uuid
import re
import scipy

from ehv import load as e_load, core

plt.rcParams['figure.facecolor'] = 'white'

numpy.random.seed(42)

# Cell
from ehv import correlation, preprocessing_pipeline
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, Normalizer
from sklearn.feature_selection import VarianceThreshold
from sklearn.decomposition import FastICA, PCA, KernelPCA
from umap import UMAP
from multiprocessing import Pool, cpu_count

# Cell
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer, make_column_selector
from sklearn.base import TransformerMixin, BaseEstimator, clone

# Cell
class GroupedTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, base_transformer, group_key, n_jobs=-1):
        self.base_transformer = base_transformer
        self.group_key = group_key
        self.n_jobs = n_jobs if n_jobs >= 1 else cpu_count()

    def fit(self, df):
        self.transformers = {}
        with Pool(processes=self.n_jobs) as pool:
            for idx, gdf in df.groupby(self.group_key):
                self.transformers[idx] = pool.apply_async(clone(self.base_transformer).fit, args=(gdf.drop(columns=self.group_key),))
            for k,v in self.transformers.items():
                self.transformers[k] = v.get()
        return self

    def transform(self, df):
        columns = df.drop(columns=self.group_key).columns
        dfs = []
        with Pool(processes=self.n_jobs) as pool:
            promises = []
            for idx, gdf in df.groupby(self.group_key):
                promises.append(pool.apply_async(self.transformers[idx].transform, args=(gdf[columns],)))
            for (promise, (idx, gdf)) in zip(promises, df.groupby(self.group_key)):
                gdf[columns] = promise.get()
                dfs.append(gdf)
        return pandas.concat(dfs)

class ColumnTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, transformer, col_selector, append=False, drop_remainder=False):
        self.transformer = transformer
        self.col_selector = col_selector
        self.append = append
        self.drop_remainder = drop_remainder

    def fit(self, df, y=None):
        self.transformer.fit(df[self.col_selector(df)])
        return self

    def transform(self, df, y=None):

        data = self.transformer.transform(df[self.col_selector(df)])
        if hasattr(data, "iloc"):
            tmp_df = data
        else:
            if len(self.col_selector(df)) == data.shape[1]:
                columns = self.col_selector(df)
            else:
                columns = ["feat_%s_%s" % (self.transformer.__class__.__name__.lower(), i) for i in range(data.shape[1])]

            tmp_df = pandas.DataFrame(
                data = data,
                columns = columns,
                index = df.index
            )

        if self.append:
            return pandas.concat([df, tmp_df], axis=1)
        elif self.drop_remainder:
            return pandas.concat([df.drop(columns=self.col_selector(df)), tmp_df], axis=1)
        else:
            df = df.copy()
            df[self.col_selector(df)] = tmp_df
            return df


class PandasVarianceThreshold(BaseEstimator, TransformerMixin):
    def __init__(self, thresh=0.0):
        self.thresh = thresh
        self.var = VarianceThreshold()

    def fit(self, X):
        self.var.fit(X)
        return self

    def transform(self, X):
        return X[X.columns[self.var.get_support()]]