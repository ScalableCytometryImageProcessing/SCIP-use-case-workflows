# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/4a_mrna_content_regression.ipynb (unless otherwise specified).

__all__ = ['run_lasso_optimization', 'run_ridge_optimization', 'compute_metrics', 'metric_funcs']

# Cell
# export

import pandas
import os
import numpy
import seaborn
import logging
import matplotlib.pyplot as plt
from importlib import reload
from ehv import core

numpy.random.seed(42)

# Cell

import time
import fcsparser
import sklearn.linear_model
import sklearn.model_selection
from functools import partial
import scipy.stats
from ehv import splits, mrna_content_regression
from joblib import load

# Cell
def run_lasso_optimization(i, j, X, y, X_test, y_test, inner_fold, inner_funcs, outer_func):
    # find best alpha
    model = sklearn.linear_model.LassoCV(fit_intercept=True, n_jobs=3, max_iter=3000, cv = sklearn.model_selection.PredefinedSplit(inner_fold))
    model.fit(X, y)

    # retrain lasso with optimal alpha on full train data
    logging.getLogger(__name__).info(f"Optimal alpha: {model.alpha_}")
    model = sklearn.linear_model.Lasso(fit_intercept=False, alpha=model.alpha_, max_iter=3000)
    model.fit(outer_func[0](X), outer_func[1](y))

    y_test_pred = model.predict(outer_func[0](X_test))

    mse = sklearn.metrics.mean_squared_error(outer_func[1](y_test), y_test_pred)

    return mse

# Cell
def run_ridge_optimization(i, j, X, y, X_test, y_test, inner_fold, inner_funcs, outer_func):
    # find best alpha
    model = sklearn.linear_model.RidgeCV(normalize=True, n_jobs=3, max_iter=5000, cv = sklearn.model_selection.PredefinedSplit(inner_fold))
    model.fit(X, y)

    # retrain lasso with optimal alpha on full train data
    logging.getLogger(__name__).info(f"Optimal alpha: {model.alpha_}")
    model = sklearn.linear_model.Ridge(fit_intercept=False, alpha=model.alpha_, max_iter=5000)
    model.fit(outer_func[0](X), outer_func[1](y))

    y_test_pred = model.predict(outer_func[0](X_test))

    mse = sklearn.metrics.mean_squared_error(outer_func[1](y_test), y_test_pred)

    return mse

# Cell

metric_funcs = [
    metrics.explained_variance_score,
    metrics.max_error,
    metrics.mean_absolute_error,
    metrics.mean_squared_error,
    metrics.mean_squared_error,
    metrics.median_absolute_error,
    metrics.r2_score
]

def compute_metrics(paths, log):
    values = {f.__name__: [] for f in metric_funcs}
    for i, (path, Xy) in enumerate(zip(paths, Xy_test)):
        regr = load(path).predict(Xy[0])
        for f in metric_funcs:
            values[f.__name__].append(f(Xy[1], regr))

    if log:
        for k,v in values.items():
            print(f"{k}: {numpy.mean(v)} +- {scipy.stats.sem(v)}")
        print("----")

    return values