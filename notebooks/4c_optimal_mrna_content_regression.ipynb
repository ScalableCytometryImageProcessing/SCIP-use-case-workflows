{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp mrna_content_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the optimal model for mRNA content regression using Optuna\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load common.py\n",
    "# export\n",
    "\n",
    "import pandas\n",
    "import os\n",
    "import numpy\n",
    "import seaborn\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<module 'ehv.core' from '/home/maximl/Data/dev/active/EhV-analysis/ehv/core.py'>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "import time\n",
    "import fcsparser\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "from functools import partial\n",
    "from ehv import mrna_content_regression, core\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn import metrics\n",
    "from joblib import load, dump\n",
    "import sklearn.neural_network\n",
    "import optuna\n",
    "import click\n",
    "import xgboost\n",
    "from multiprocessing import cpu_count, Pool\n",
    "\n",
    "reload(core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "core.load_config(\"../config_cn1346.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta, df = fcsparser.parse(core.FCS_NONINTENSITY)\n",
    "df_meta = df[[\"label\", \"replicate\", \"timepoint\"]].astype(int)\n",
    "df_meta[\"timepoint\"] = df_meta[\"timepoint\"].map(lambda a: meta[\"timepoint\"].split(\",\")[a])\n",
    "df_meta[\"replicate\"] = df_meta[\"replicate\"].map(lambda a: meta[\"replicate\"].split(\",\")[a])\n",
    "df = df.drop(columns=[\"label\", \"replicate\", \"timepoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, fluor_df = fcsparser.parse(core.FCS_FLUOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_funcs = [\n",
    "    metrics.explained_variance_score,\n",
    "    metrics.max_error,\n",
    "    metrics.mean_absolute_error,\n",
    "    metrics.mean_squared_error,\n",
    "    metrics.mean_squared_error,\n",
    "    metrics.median_absolute_error,\n",
    "    metrics.r2_score\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BF regression on targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_df = df.filter(regex=\"(i?).*BF.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_fold, inner_folds = load(core.FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def standardizer(X, mean, std=1.0):\n",
    "    return (X-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def preprocess_funcs(df, target, outer_fold, inner_folds):\n",
    "\n",
    "    outer_fold_funcs = []\n",
    "    inner_fold_funcs = []\n",
    "\n",
    "    for i, (train_idx, _) in enumerate(PredefinedSplit(outer_fold).split()):\n",
    "\n",
    "        X = df.iloc[train_idx]\n",
    "        y = target.iloc[train_idx]\n",
    "\n",
    "        outer_fold_funcs.append((\n",
    "            partial(standardizer, mean=X.mean(), std=X.std()),\n",
    "            partial(standardizer, mean=y.mean())\n",
    "        ))\n",
    "\n",
    "        for inner_fold in inner_folds[i]:\n",
    "            tmp = []\n",
    "            for nested_train_idx, _ in PredefinedSplit(inner_fold).split():\n",
    "\n",
    "                X_train = X.iloc[nested_train_idx]\n",
    "                mean, std = X.mean(), X.std()\n",
    "\n",
    "                y_mean = y.iloc[nested_train_idx].mean()\n",
    "\n",
    "                tmp.append((\n",
    "                    partial(standardizer, mean=mean, std=std),\n",
    "                    partial(standardizer, mean=y_mean)\n",
    "                ))\n",
    "\n",
    "            inner_fold_funcs.append(tmp)\n",
    "            \n",
    "    return outer_fold_funcs, inner_fold_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_tmr_funcs = preprocess_funcs(bf_df, fluor_df[\"IntensityMCTMRlogicle\"], outer_fold, inner_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def define_dummy(trial):\n",
    "    return sklearn.dummy.DummyRegressor()\n",
    "\n",
    "def define_mlp(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 10)\n",
    "    layers = []\n",
    "    for i in range(n_layers):\n",
    "        layers.append(trial.suggest_int(f\"hidden_layer_size_{i}\", 10, 100))\n",
    "\n",
    "    return sklearn.neural_network.MLPRegressor(\n",
    "        hidden_layer_sizes = layers,\n",
    "        activation = trial.suggest_categorical(\"activation\", ['identity', 'logistic', 'tanh', 'relu']),\n",
    "        learning_rate_init = trial.suggest_float('learning_rate_init', 1e-4, 1e-1, log=True)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def define_xgb(trial):\n",
    "    return xgboost.XGBRegressor(\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 400),\n",
    "        tree_method = \"gpu_hist\",\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        subsample = trial.suggest_float('subsample', 0.1, 1.0)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def define_sgd(trial):\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [\"constant\", \"optimal\"])\n",
    "    if learning_rate == \"constant\":\n",
    "        eta0 = trial.suggest_float('eta0', 1e-4, 1e-1, log=True)\n",
    "    else:\n",
    "        eta0 = 0.01 # default\n",
    "\n",
    "    return sklearn.linear_model.SGDRegressor(\n",
    "        loss = trial.suggest_categorical(\"loss\", ['squared_loss', 'huber']),\n",
    "        fit_intercept = False,\n",
    "        learning_rate = learning_rate,\n",
    "        eta0 = trial.suggest_float('eta0', 1e-4, 1e-1, log=True),\n",
    "        alpha = trial.suggest_float(\"alpha\", 0, 1)\n",
    "    )\n",
    "\n",
    "definition_dict = {\n",
    "    \"mlp\": define_mlp,\n",
    "    \"sgd\": define_sgd,\n",
    "    \"xgb\": define_xgb,\n",
    "    \"dummy\": define_dummy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def objective(trial, inner_fold, funcs, X, y, model_names):\n",
    "    \n",
    "    logging.getLogger(__name__).info(model_names)\n",
    "    \n",
    "    model_name = trial.suggest_categorical(\"model_name\", model_names)\n",
    "    model = definition_dict[model_name](trial)\n",
    "    \n",
    "    scores = []\n",
    "    for i, (func, (train_idx, val_idx)) in enumerate(zip(funcs, PredefinedSplit(inner_fold).split())):\n",
    "        logging.getLogger(__name__).info(f\"Fitting model on inner fold {i}\")\n",
    "        \n",
    "        X_train = func[0](X.iloc[train_idx])\n",
    "        y_train = func[1](y.iloc[train_idx])\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        X_val = func[0](X.iloc[val_idx])\n",
    "        y_val = func[1](y.iloc[val_idx])\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        scores.append(sklearn.metrics.mean_squared_error(y_val, y_val_pred))\n",
    "        \n",
    "    return numpy.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def run_optimization(i, j, X, y, inner_fold, funcs, model_names, optuna_storage, optuna_n_trials, optuna_study_name_fmt, optuna_n_jobs):\n",
    "    fold_objective = partial(objective, inner_fold=inner_fold, funcs=funcs, X=X, y=y, model_names=model_names)\n",
    "\n",
    "    # select best parameters for model using Optuna\n",
    "\n",
    "    logging.getLogger(__name__).info(f\"(outer {i}, repeat {j}) Study started\")\n",
    "\n",
    "    study = optuna.create_study(study_name=optuna_study_name_fmt % (i, j), direction='minimize', storage=optuna_storage, load_if_exists=True)\n",
    "    study.set_user_attr(\"cross-validation splits\", core.FOLDS)\n",
    "    study.optimize(fold_objective, n_trials=optuna_n_trials, n_jobs=optuna_n_jobs)\n",
    "\n",
    "    # retrain model with best parameters on train+val data\n",
    "\n",
    "    logging.getLogger(__name__).info(f\"(outer {i}, repeat {j}) Retraining model with best params\")\n",
    "\n",
    "    fixed_trial = optuna.trial.FixedTrial(study.best_params)\n",
    "    model = definition_dict[fixed_trial.params[\"model_name\"]](fixed_trial)\n",
    "\n",
    "    model.fit(outer_func[0](X), outer_func[1](y))\n",
    "\n",
    "    # predict X_test with retrained model\n",
    "    X_test = outer_func[0](df.iloc[test_idx])\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluate predictions\n",
    "    y_test = outer_func[1](target.iloc[test_idx])\n",
    "\n",
    "    return sklearn.metrics.mean_squared_error(y_test, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def nested_cross_validation_with_hyperparam_optimization(\n",
    "        df:pandas.DataFrame, target:pandas.Series, model_names:str,\n",
    "        optuna_storage:str, optuna_n_trials:int, optuna_study_name_fmt:str, optuna_n_jobs:int,\n",
    "        n_procs:int\n",
    "    ):\n",
    "    \n",
    "    outer_fold, inner_folds = load(core.FOLDS)\n",
    "    outer_fold_funcs, inner_folds_funcs = preprocess_funcs(df, target, outer_fold, inner_folds)\n",
    "    \n",
    "    with Pool(processes=n_procs) as pool:\n",
    "        # submit all optimization tasks to the pool\n",
    "        promises = []\n",
    "        for i, ((train_idx, test_idx), outer_func) in enumerate(zip(PredefinedSplit(outer_fold).split(), outer_fold_funcs)):\n",
    "\n",
    "            X = df.iloc[train_idx]\n",
    "            y = target.iloc[train_idx]\n",
    "\n",
    "            promises_inner = []\n",
    "            for j, (inner_fold, funcs) in enumerate(zip(inner_folds[i], inner_folds_funcs)):\n",
    "\n",
    "                # add func to pool\n",
    "                logging.getLogger(__name__).info(f\"Hyper param tuning on outer fold {i}, inner fold repeat {j+1}/{len(inner_folds)}\")\n",
    "                args=(i, j, X, y, inner_fold, funcs, model_names, optuna_storage, optuna_n_trials, optuna_study_name_fmt, optuna_n_jobs)\n",
    "                promises_inner.append(pool.apply_async(run_optimization, args=args))\n",
    "\n",
    "            promises.append(promises_inner)\n",
    "\n",
    "        # retrieve scores from pool once finished\n",
    "        scores = []\n",
    "        for promises_inner in promises:\n",
    "            scores_inner = []\n",
    "            for promise in promises_inner:\n",
    "                scores_inner.append(promise.get())\n",
    "            scores.append(scores_inner)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:__main__:Hyper param tuning on outer fold 0, inner fold repeat 1/3\nINFO:__main__:Hyper param tuning on outer fold 0, inner fold repeat 2/3\nINFO:__main__:Hyper param tuning on outer fold 0, inner fold repeat 3/3\nINFO:__main__:Hyper param tuning on outer fold 1, inner fold repeat 1/3\nINFO:__main__:Hyper param tuning on outer fold 1, inner fold repeat 2/3\nINFO:__main__:Hyper param tuning on outer fold 1, inner fold repeat 3/3\nINFO:__main__:Hyper param tuning on outer fold 2, inner fold repeat 1/3\nINFO:__main__:Hyper param tuning on outer fold 2, inner fold repeat 2/3\nINFO:__main__:Hyper param tuning on outer fold 2, inner fold repeat 3/3\nINFO:__main__:(outer 0, repeat 0) Study started\n[I 2020-08-27 11:18:35,099] Using an existing study with name 'test_run_2_0_0' instead of creating a new one.\nINFO:__main__:(outer 0, repeat 1) Study started\nINFO:__main__:['xgb']\n[I 2020-08-27 11:18:35,176] Using an existing study with name 'test_run_2_0_1' instead of creating a new one.\nINFO:__main__:Fitting model on inner fold 0\nINFO:__main__:['xgb']\nINFO:__main__:Fitting model on inner fold 0\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1930e16a5d25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m scores = nested_cross_validation_with_hyperparam_optimization(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mbf_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfluor_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"IntensityMCTMRlogicle\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"xgb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sqlite:///tmp/test.sqlite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test_run_2_%d_%d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-18-6efdbe5420ee>\u001b[0m in \u001b[0;36mnested_cross_validation_with_hyperparam_optimization\u001b[0;34m(df, target, model_names, optuna_storage, optuna_n_trials, optuna_study_name_fmt, optuna_n_jobs, n_procs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mscores_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpromise\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpromises_inner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mscores_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpromise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_inner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = nested_cross_validation_with_hyperparam_optimization(\n",
    "    bf_df, fluor_df[\"IntensityMCTMRlogicle\"],\n",
    "    [\"xgb\"], \"sqlite:///tmp/test.sqlite\", 2, \"test_run_2_%d_%d\", 1, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "@click.command()\n",
    "@click.option(\"--target-col\", \"-t\", type=str, default=\"IntensityMCTMRlogicle\")\n",
    "@click.option(\"--storage-path\", \"-s\", type=click.Path(file_okay=False, exists=False), required=True, help=\"Provide absolute path.\")\n",
    "@click.option(\"--model\", \"-m\", type=click.Choice(definition_dict.keys()), multiple=True, default=definition_dict.keys())\n",
    "@click.option(\"--config\", \"-c\", type=click.Path(dir_okay=False, exists=True), default=\"../config_cn1346.yml\")\n",
    "@click.option(\"--optuna-n-trials\", \"-ot\", type=click.IntRange(0), default=5)\n",
    "@click.option(\"--optuna-study-name\", \"-on\", type=str, default=\"study\")\n",
    "@click.option(\"--optuna-n-jobs\", \"-oj\", type=int, default=-1)\n",
    "@click.option(\"--n-procs\", \"-p\", type=int, default=-1)\n",
    "@click.option(\"--overwrite\", \"-w\", is_flag=True, default=False)\n",
    "@click.option(\"--verbose\", \"-v\", is_flag=True, default=False)\n",
    "def nested_cross_validation_with_hyperparam_optimization_command(target_col, storage_path, model, config, optuna_n_trials, optuna_study_name, optuna_n_jobs, n_procs, overwrite, verbose):\n",
    "    \n",
    "    if optuna_n_jobs == -1:\n",
    "        optuna_n_jobs = cpu_count()\n",
    "    if n_procs == -1:\n",
    "        n_procs = cpu_count()\n",
    "    \n",
    "    core.load_config(config)\n",
    "    \n",
    "    logging.basicConfig(level=logging.DEBUG if verbose else logging.INFO)\n",
    "    \n",
    "    meta, df = fcsparser.parse(core.FCS_NONINTENSITY)\n",
    "    df_meta = df[[\"label\", \"replicate\", \"timepoint\"]].astype(int)\n",
    "    df_meta[\"timepoint\"] = df_meta[\"timepoint\"].map(lambda a: meta[\"timepoint\"].split(\",\")[a])\n",
    "    df_meta[\"replicate\"] = df_meta[\"replicate\"].map(lambda a: meta[\"replicate\"].split(\",\")[a])\n",
    "    df = df.drop(columns=[\"label\", \"replicate\", \"timepoint\"])\n",
    "    \n",
    "    _, fluor_df = fcsparser.parse(core.FCS_FLUOR)\n",
    "    \n",
    "    df = bf_df = df.filter(regex=\"(i?).*BF.*\")\n",
    "    target = fluor_df[target_col]\n",
    "    \n",
    "    optuna_storage = \"sqlite:////\"+os.path.join(storage_path, \"optuna_db.sqlite\")\n",
    "    \n",
    "    if overwrite and os.path.isfile(optuna_storage):\n",
    "        os.remove(optuna_storage)\n",
    "        \n",
    "    optuna_study_name_fmt = optuna_study_name + \"_%d_%d\"\n",
    "    \n",
    "    scores = nested_cross_validation_with_hyperparam_optimization(df, target, model, optuna_storage, optuna_n_trials, optuna_study_name_fmt, optuna_n_jobs, n_procs)\n",
    "    \n",
    "    dump(scores, os.path.join(storage_path, \"scores.dat\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}